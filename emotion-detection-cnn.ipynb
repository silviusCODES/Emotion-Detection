{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":234911,"sourceType":"datasetVersion","datasetId":99505}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\n\n# Importing Deep Learning Libraries\n\nfrom tensorflow.keras.utils import load_img, img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\nfrom keras.models import Model,Sequential\nfrom keras.optimizers import Adam,SGD,RMSprop","metadata":{"execution":{"iopub.status.busy":"2023-11-04T21:18:11.082770Z","iopub.execute_input":"2023-11-04T21:18:11.083378Z","iopub.status.idle":"2023-11-04T21:18:20.942724Z","shell.execute_reply.started":"2023-11-04T21:18:11.083338Z","shell.execute_reply":"2023-11-04T21:18:20.941873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Displaying Images","metadata":{}},{"cell_type":"code","source":"picture_size = 48\nfolder_path = \"../input/face-expression-recognition-dataset/images/\"\nexpression = 'disgust'\n\n\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n    plt.imshow(img)   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-04T21:18:29.046783Z","iopub.execute_input":"2023-11-04T21:18:29.047459Z","iopub.status.idle":"2023-11-04T21:18:30.558297Z","shell.execute_reply.started":"2023-11-04T21:18:29.047423Z","shell.execute_reply":"2023-11-04T21:18:30.557398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Training and Validation Data","metadata":{}},{"cell_type":"code","source":"batch_size  = 128\n\ndatagen_train  = ImageDataGenerator()\ndatagen_val = ImageDataGenerator()\n\ntrain_set = datagen_train.flow_from_directory(folder_path+\"train\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)\n\n\ntest_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T21:19:32.084086Z","iopub.execute_input":"2023-11-04T21:19:32.084900Z","iopub.status.idle":"2023-11-04T21:19:58.667181Z","shell.execute_reply.started":"2023-11-04T21:19:32.084868Z","shell.execute_reply":"2023-11-04T21:19:58.666266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"from keras.optimizers import Adam,SGD,RMSprop\n\n\nno_of_classes = 7\n\nmodel = Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(learning_rate = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-04T21:20:01.838995Z","iopub.execute_input":"2023-11-04T21:20:01.839417Z","iopub.status.idle":"2023-11-04T21:20:06.963829Z","shell.execute_reply.started":"2023-11-04T21:20:01.839382Z","shell.execute_reply":"2023-11-04T21:20:06.962131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting the Data with Training and Validation Data","metadata":{}},{"cell_type":"code","source":"from keras.optimizers import RMSprop,SGD,Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"./model2.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n\nepochs = 48\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T21:20:11.348215Z","iopub.execute_input":"2023-11-04T21:20:11.349123Z","iopub.status.idle":"2023-11-04T21:20:11.355707Z","shell.execute_reply.started":"2023-11-04T21:20:11.349092Z","shell.execute_reply":"2023-11-04T21:20:11.354522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=train_set,\n                                steps_per_epoch=train_set.n//train_set.batch_size,\n                                epochs=epochs,\n                                validation_data = test_set,\n                                validation_steps = test_set.n//test_set.batch_size,\n                                callbacks=callbacks_list\n                                )","metadata":{"execution":{"iopub.status.busy":"2023-11-04T21:38:08.627911Z","iopub.execute_input":"2023-11-04T21:38:08.628279Z","iopub.status.idle":"2023-11-04T21:50:58.749998Z","shell.execute_reply.started":"2023-11-04T21:38:08.628246Z","shell.execute_reply":"2023-11-04T21:50:58.749086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting Accuracy & Loss","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-04T21:51:54.818862Z","iopub.execute_input":"2023-11-04T21:51:54.819231Z","iopub.status.idle":"2023-11-04T21:52:52.635015Z","shell.execute_reply.started":"2023-11-04T21:51:54.819200Z","shell.execute_reply":"2023-11-04T21:52:52.634017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./model2.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-04T21:53:09.817100Z","iopub.execute_input":"2023-11-04T21:53:09.817469Z","iopub.status.idle":"2023-11-04T21:53:09.969000Z","shell.execute_reply.started":"2023-11-04T21:53:09.817439Z","shell.execute_reply":"2023-11-04T21:53:09.968038Z"},"trusted":true},"execution_count":null,"outputs":[]}]}